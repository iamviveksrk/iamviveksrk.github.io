<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Regularization &amp; Validation ‚Äì üéê</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">üéê</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../mlt_taship/w3_k_means_validation.html">MLT TAship</a></li><li class="breadcrumb-item"><a href="../mlt_taship/w6_regularization_validation.html">Regularization &amp; Validation</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Intro to DS&amp;AI for Std-XI students</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../std_xi_workshop/embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Embeddings - Slide Deck</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../std_xi_workshop/hierarchical_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hierarchical Clustering - Slide Deck</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">ML Handbook</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml_handbook/inductive_bias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inductive Bias in ML Algorithms</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml_handbook/ordinal_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ordinal Regression/Classification (Both works)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml_handbook/em.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to EM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml_handbook/ppca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probabilistic PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml_handbook/agglomerative_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hierarchical Clustering</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">MLT TAship</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mlt_taship/w3_k_means_validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">K-Means &amp; K-Means++</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mlt_taship/w6_regularization_validation.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Regularization &amp; Validation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mlt_taship/w9_perceptron_lr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Perceptron &amp; Logistic Regression</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#data-generation-with-correlated-features" id="toc-data-generation-with-correlated-features" class="nav-link active" data-scroll-target="#data-generation-with-correlated-features">Data Generation with correlated features</a></li>
  <li><a href="#maximum-likelihood-estimator-for-finding-w" id="toc-maximum-likelihood-estimator-for-finding-w" class="nav-link" data-scroll-target="#maximum-likelihood-estimator-for-finding-w">Maximum-Likelihood Estimator for finding <strong>w</strong></a></li>
  <li><a href="#goodness-of-ml-estimator" id="toc-goodness-of-ml-estimator" class="nav-link" data-scroll-target="#goodness-of-ml-estimator">Goodness of ML Estimator</a>
  <ul class="collapse">
  <li><a href="#bias-variance-decomposition-of-mse" id="toc-bias-variance-decomposition-of-mse" class="nav-link" data-scroll-target="#bias-variance-decomposition-of-mse">Bias-Variance Decomposition of MSE</a>
  <ul class="collapse">
  <li><a href="#applying-bias-variance-decomposition-on-ml-estimator-of-w" id="toc-applying-bias-variance-decomposition-on-ml-estimator-of-w" class="nav-link" data-scroll-target="#applying-bias-variance-decomposition-on-ml-estimator-of-w">Applying Bias-Variance decomposition on ML Estimator of <strong>w</strong></a></li>
  <li><a href="#derivation-of-decomposition" id="toc-derivation-of-decomposition" class="nav-link" data-scroll-target="#derivation-of-decomposition">Derivation of decomposition</a></li>
  </ul></li>
  <li><a href="#in-pursuit-of-a-better-estimator" id="toc-in-pursuit-of-a-better-estimator" class="nav-link" data-scroll-target="#in-pursuit-of-a-better-estimator">In pursuit of a <em>better</em> estimator</a>
  <ul class="collapse">
  <li><a href="#reducing-the-trace-value" id="toc-reducing-the-trace-value" class="nav-link" data-scroll-target="#reducing-the-trace-value">Reducing the Trace value</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#ridge-regression" id="toc-ridge-regression" class="nav-link" data-scroll-target="#ridge-regression">Ridge Regression</a>
  <ul class="collapse">
  <li><a href="#closed-form-solution-for-ridge-estimator" id="toc-closed-form-solution-for-ridge-estimator" class="nav-link" data-scroll-target="#closed-form-solution-for-ridge-estimator">Closed-Form Solution for Ridge Estimator</a></li>
  </ul></li>
  <li><a href="#comparison-of-ridge-and-linear-regression-solutions" id="toc-comparison-of-ridge-and-linear-regression-solutions" class="nav-link" data-scroll-target="#comparison-of-ridge-and-linear-regression-solutions">Comparison of Ridge and Linear Regression Solutions</a></li>
  <li><a href="#lasso-regression" id="toc-lasso-regression" class="nav-link" data-scroll-target="#lasso-regression">Lasso Regression</a>
  <ul class="collapse">
  <li><a href="#solution-for-lasso-regression" id="toc-solution-for-lasso-regression" class="nav-link" data-scroll-target="#solution-for-lasso-regression">Solution for Lasso Regression</a></li>
  </ul></li>
  <li><a href="#best-Œª" id="toc-best-Œª" class="nav-link" data-scroll-target="#best-Œª">Best Œª?</a>
  <ul class="collapse">
  <li><a href="#validation" id="toc-validation" class="nav-link" data-scroll-target="#validation">Validation</a></li>
  <li><a href="#k-fold-cross-validation" id="toc-k-fold-cross-validation" class="nav-link" data-scroll-target="#k-fold-cross-validation">K-Fold Cross Validation</a></li>
  <li><a href="#leave-one-out-cross-validation" id="toc-leave-one-out-cross-validation" class="nav-link" data-scroll-target="#leave-one-out-cross-validation">Leave-one-out Cross Validation</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../mlt_taship/w3_k_means_validation.html">MLT TAship</a></li><li class="breadcrumb-item"><a href="../mlt_taship/w6_regularization_validation.html">Regularization &amp; Validation</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Regularization &amp; Validation</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="data-generation-with-correlated-features" class="level2">
<h2 class="anchored" data-anchor-id="data-generation-with-correlated-features">Data Generation with correlated features</h2>
<p>For an input <span class="math inline">\(x_i\)</span>, we generate a label <span class="math inline">\(y_i\)</span> by using a fixed <span class="math inline">\(\mathbf{w}\)</span> and a random normal variable <span class="math inline">\(œµ ‚àº N(0, 0.1^2)\)</span> in the following fashion:</p>
<p><span class="math display">\[ y_i = \mathbf{w}^{T}x_i + œµ\]</span></p>
<p>We generate a dataset with 100 samples, each having 50 features. We sample the first 25 features from a gaussian - meaning they are uncorrelated, and add 25 more features that are linearly correlated with the current ones.</p>
<div id="cell-3" class="cell" data-executioninfo="{&quot;elapsed&quot;:3468,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1698641925161,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vivek Sivaramakrishnan&quot;,&quot;userId&quot;:&quot;13013544173607732074&quot;},&quot;user_tz&quot;:-330}" data-outputid="c20cb981-7c23-4bfc-cd21-d8e2827c5dee">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_regression</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset with 25 uncorrelated features</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">7</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># X = np.random.normal(size=(n, d))</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_regression(n_samples<span class="op">=</span>n, n_features<span class="op">=</span>d, noise<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Add 25 correlated features:</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(d):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  a <span class="op">=</span> np.random.normal(size<span class="op">=</span>d<span class="op">+</span>j)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  new_feature <span class="op">=</span> X<span class="op">@</span>np.vectorize(<span class="kw">lambda</span> i: <span class="bu">int</span>(i)<span class="op">*</span>np.random.randint(<span class="op">-</span><span class="dv">2</span>, high<span class="op">=</span><span class="dv">2</span>))(a<span class="op">&gt;</span><span class="dv">1</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  X <span class="op">=</span> np.c_[X, new_feature]</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.T</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>plt.matshow(np.corrcoef(X))</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>cb <span class="op">=</span> plt.colorbar()</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>cb.ax.tick_params()</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Correlation Matrix'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="w6_regularization_validation_files/figure-html/cell-2-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We then make a sparse <span class="math inline">\(\mathbf{w}\)</span> vector with 10/50 features non-zero. We use this to generate <span class="math inline">\(\mathbf{y}\)</span> using the model discussed above.</p>
<div id="cell-5" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>d <span class="op">*=</span> <span class="dv">2</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">69</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>r_d <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Make sparse w with 10 features</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> np.zeros(d)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>relevant <span class="op">=</span> np.random.randint(<span class="dv">0</span>, high<span class="op">=</span>d<span class="op">-</span><span class="dv">1</span>, size<span class="op">=</span>r_d)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign some weight to these features only</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>w[relevant] <span class="op">=</span> np.random.normal(scale<span class="op">=</span><span class="dv">2</span>, size<span class="op">=</span>r_d)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create some noise, and find predictors</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> w.T <span class="op">@</span> X <span class="op">+</span> np.random.normal(scale<span class="op">=</span><span class="fl">0.01</span>, size<span class="op">=</span>n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="maximum-likelihood-estimator-for-finding-w" class="level1">
<h1>Maximum-Likelihood Estimator for finding <strong>w</strong></h1>
<p>The closed form solution for the ML estimator to solve the linear regression problem with the given probabilistic model is the following:</p>
<p><span class="math display">\[\hat{\mathbf{w}}_{ML} = (XX^T)^‚Ä†Xy\]</span></p>
<div id="cell-7" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>w_hat_ml <span class="op">=</span> np.linalg.pinv(X <span class="op">@</span> X.T) <span class="op">@</span> X <span class="op">@</span> y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="goodness-of-ml-estimator" class="level1">
<h1>Goodness of ML Estimator</h1>
<p>To quantify ‚Äúgoodness‚Äù of our estimator, we look at the <strong>Mean Squared Error</strong>.</p>
<p><strong>Mean Squared Error</strong>: Let <span class="math inline">\(\mathbf{\hat{w}}\)</span> be an estimator of an unknown parameter <span class="math inline">\(\mathbf{w}\)</span>. Then we define</p>
<p><span class="math display">\[\text{MSE}(\mathbf{\hat{w}}) = \mathbb{E}[||\mathbf{\hat{w}} - \mathbf{w}||^2]\]</span></p>
<p>as the Mean Squared Error of our estimator.</p>
<section id="bias-variance-decomposition-of-mse" class="level2">
<h2 class="anchored" data-anchor-id="bias-variance-decomposition-of-mse">Bias-Variance Decomposition of MSE</h2>
<p>The above formula for mean squared error can be rewritten as</p>
<p><span class="math display">\[\text{MSE}(\mathbf{\hat{w}}) = \text{tr}(\text{Var}(\mathbf{\hat{w}})) + ||\text{Bias}(\mathbf{\hat{w}})||^2\]</span></p>
<p>where <span class="math inline">\(\text{tr}(\text{Var}(\mathbf{\hat{w}}))\)</span> is the trace of the covariance matrix, and <span class="math display">\[\text{Bias}(\mathbf{\hat{w}}) = \mathbb{E}[\mathbf{\hat{w}}] - \mathbf{w}\]</span></p>
<p>is the bias, i.e, the expected difference between the estimator <span class="math inline">\(\mathbf{\hat{w}}\)</span> and true value <span class="math inline">\(\mathbf{w}\)</span>.</p>
<section id="applying-bias-variance-decomposition-on-ml-estimator-of-w" class="level3">
<h3 class="anchored" data-anchor-id="applying-bias-variance-decomposition-on-ml-estimator-of-w">Applying Bias-Variance decomposition on ML Estimator of <strong>w</strong></h3>
<p>The ML Estimator has zero bias; so we get</p>
<p><span class="math display">\[\begin{alignat}{2}
&amp;&amp; \text{MSE}(\mathbf{\hat{w}}_{ML})
&amp; = \text{tr}(\text{Var}(\mathbf{\hat{w}}_{ML})) \\
&amp;&amp;
&amp; = \sigma^2 Ãá* \text{tr}((XX^T)^{-1})
\end{alignat}\]</span></p>
</section>
<section id="derivation-of-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="derivation-of-decomposition">Derivation of decomposition</h3>
<p>We use the below well-known formula relating the covariance matrix <span class="math inline">\(\text{Var}(X)\)</span> to the first and second moments: <span class="math display">\[\mathbb{E}[X^2] = (\mathbb{E}[X])^2 + \text{Var}(X)\]</span></p>
<p>Therefore we have,</p>
<p><span class="math display">\[
\begin{alignat}{2}
&amp;&amp; \text{MSE}(\mathbf{\hat{w}})
&amp; = \mathbb{E}[||\mathbf{\hat{w}} - \mathbf{w}||^2] \\
&amp;&amp; &amp; = (\mathbb{E}[||\mathbf{\hat{w}} - \mathbf{w}||])^2 + \text{Var}(||\mathbf{\hat{w}} - \mathbf{w}||)\\
&amp;&amp; &amp; = ||\mathbb{E}[\mathbf{\hat{w}}] - \mathbf{w}||^2 + \text{Var}(||\mathbf{\hat{w}}||) \\
&amp;&amp; &amp; = ||\text{Bias}(\mathbf{\hat{w}})||^2 + \text{tr}(\text{Var}(\mathbf{\hat{w}}))
\end{alignat}
\]</span></p>
<p>Source: <a href="https://en.wikipedia.org/wiki/Mean_squared_error#Proof_of_variance_and_bias_relationship">Wikipedia</a></p>
</section>
</section>
<section id="in-pursuit-of-a-better-estimator" class="level2">
<h2 class="anchored" data-anchor-id="in-pursuit-of-a-better-estimator">In pursuit of a <em>better</em> estimator</h2>
<p>We see that the goodness of the ML estimate depends on the variance of error <span class="math inline">\(œÉ^2\)</span> and <span class="math inline">\(\text{tr}((XX^T)^{-1})\)</span>. We would like to reduce this quantity.</p>
<p>The variance of error is inherent to the experimental setup, and reduction of this quantity therefore depends on qualitative improvements of instruments/peripherals used to collect data. So we cannot hope to reduce this quantity from a mathematical perspective.</p>
<p>The trace depends on <span class="math inline">\((XX^T)^{-1}\)</span>, which denotes the inverse covariance matrix of the data <span class="math inline">\(X\)</span>. The covariance matrix captures how the features are related with each other, and it seems that this relation affects the goodness of our estimator. We may try to tweak this value to reduce the trace value, thereby increasing the goodness of our ML estimator.</p>
<section id="reducing-the-trace-value" class="level3">
<h3 class="anchored" data-anchor-id="reducing-the-trace-value">Reducing the Trace value</h3>
<p>The trace of a matrix <span class="math inline">\(X\)</span> can also be represented as the sum of the eigenvalues of <span class="math inline">\(X\)</span>.</p>
<p>Let <span class="math inline">\(\mathbf{Œª}\)</span> denote the set of eigenvalues of <span class="math inline">\(XX^T\)</span>. Then <span class="math display">\[\{ \frac{1}{Œª_i} \; ‚àÄ \; i \; \epsilon \; \{1, 2, .., n\} \}\]</span> is the set of eigenvalues of <span class="math inline">\((XX^T)^{-1}\)</span> and its trace thus is the following:</p>
<p><span class="math display">\[\text{tr}((XX^T)^{-1}) = \sum_{i=1}^{d}\frac{1}{Œª_i}\]</span></p>
<p>Now, we‚Äôd like to reduce this value. A way forward would be to increase the eigenvalues of <span class="math inline">\(XX^T\)</span> by doing the following:</p>
<p><span class="math display">\[\text{eigenvalues of } (XX^T + ŒªI) = \{ Œª_i + Œª \; ‚àÄ \; i \; \epsilon \; \{1, 2, .., n\} \}\]</span></p>
<p>which will result in a smaller trace value (due to increase in denominator): <span class="math display">\[\text{tr}((XX^T + ŒªI)^{-1}) = \sum_{i=1}^{d}\frac{1}{Œª_i + Œª}\]</span></p>
<p>However, this process reformulates the problem the estimator is trying to solve (trade-off) to the following:</p>
<p><span class="math display">\[\hat{\mathbf{w}}_{\lambda - ML} = (XX^T + ŒªI)^{-1}Xy\]</span></p>
<p>This induces a non-zero bias in our estimator:</p>
<p><span class="math display">\[
\begin{alignat}{2}
&amp;&amp; \text{Bias}(\mathbf{\hat{w}}_{\lambda-ML})
&amp; = \mathbb{E}[\mathbf{\hat{w}}_{\lambda-ML}] - \mathbf{w}\\
&amp;&amp; &amp; = [(XX^T + ŒªI)^{-1} - (XX^T)^‚Ä†](XX^T)\mathbf{w}
\end{alignat}
\]</span></p>
<p>The difference between the MSE of our estimators is then:</p>
<p><span class="math display">\[
\begin{alignat}{3}
&amp;&amp;&amp; \text{MSE}(\mathbf{\hat{w}}) - \text{MSE}(\mathbf{\hat{w}}_{\lambda-ML})
&amp;&amp; = \text{tr}(\text{Var}(\mathbf{\hat{w}})) - \text{tr}(\text{Var}(\mathbf{\hat{w}}_{\lambda-ML}))
&amp; \quad - \quad\text{(A)} \\
&amp;&amp;&amp; &amp;&amp; \quad - || \text{Bias}(\mathbf{\hat{w}}_{\lambda-ML}) ||^2
&amp; \quad - \quad\text{(B)} \\
\end{alignat}
\]</span></p>
<p>Note that both <span class="math inline">\(\text{(A)}\)</span> and <span class="math inline">\(\text{(B)}\)</span> are <em>positive</em> quantities, hence the difference can either be <em>positive</em> or <em>negative</em>; The difference depends on the parameter <span class="math inline">\(\lambda\)</span>.</p>
<p>The existence theorem asserts that there exists some <strong>non-zero</strong> <span class="math inline">\(Œª\)</span> such that the MSE of <span class="math inline">\(\hat{\mathbf{w}}_{\lambda - ML}\)</span> is lower than that of <span class="math inline">\(\hat{\mathbf{w}}_{ML}\)</span>, i.e we get <span class="math inline">\(\text{(A)} &gt; \text{(B)}\)</span>.</p>
</section>
</section>
</section>
<section id="ridge-regression" class="level1">
<h1>Ridge Regression</h1>
<p>The method of estimating <span class="math inline">\(w\)</span> while reducing the effect inter-correlated variables have on the ML estimator for linear regression is called Ridge Regression.</p>
<p>The objective of the ridge regression problem is given as follows:</p>
<p><span class="math display">\[\underset{w}{\arg \min} \sum_{i=1}^{n}(w^Tx_i-y_i)^2 + Œª||w||^2_2\]</span></p>
<p>The <span class="math inline">\(Œª\)</span> term is called the regularizer, and is a hyperparameter, which can be chosen through the cross-validation technique, described at the end of this notebook.</p>
<section id="closed-form-solution-for-ridge-estimator" class="level2">
<h2 class="anchored" data-anchor-id="closed-form-solution-for-ridge-estimator">Closed-Form Solution for Ridge Estimator</h2>
<p>It is the same as the aforementioned <span class="math inline">\(\hat{\mathbf{w}}_{\lambda - ML}\)</span>:</p>
<p><span class="math display">\[\hat{\mathbf{w}}_{\lambda - ML} = (XX^T + ŒªI)^{-1}Xy\]</span></p>
<p>It‚Äôs good to know that the inverse of <span class="math inline">\((XX^T + ŒªI)\)</span> always exists since: 1. <span class="math inline">\((XX^T)\)</span> is positive semi-definite 2. <span class="math inline">\(\lambda &gt; 0\)</span></p>
<p>Hence <span class="math inline">\((XX^T + ŒªI)\)</span> is a positive definite matrix (i.e.&nbsp;all eigenvalues are strictly positive - full rank) - indicating its inverse <strong>exists</strong>.</p>
<div id="cell-15" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>l <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>w_hat_ridge <span class="op">=</span> np.linalg.inv(X <span class="op">@</span> X.T <span class="op">+</span> l <span class="op">*</span> np.eye(d)) <span class="op">@</span> X <span class="op">@</span> y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="comparison-of-ridge-and-linear-regression-solutions" class="level1 page-columns page-full">
<h1>Comparison of Ridge and Linear Regression Solutions</h1>
<p>The <span class="math inline">\(\lambda ||w||^2_2\)</span> term in the objective function for Ridge regression penalizes the score for <span class="math inline">\(w\)</span>‚Äôs with greater length. This thus pushes the ridge estimator closer to the origin, resulting in smaller values in its components.</p>
<p>We show the effect of varying <span class="math inline">\(\lambda\)</span> over the coefficients of ridge</p>
<div id="cell-17" class="cell page-columns page-full" data-executioninfo="{&quot;elapsed&quot;:4405,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1698645004545,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vivek Sivaramakrishnan&quot;,&quot;userId&quot;:&quot;13013544173607732074&quot;},&quot;user_tz&quot;:-330}" data-outputid="f983bddc-e798-4d5d-c7bd-bbf587c869d9">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>lambdas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">10</span> , <span class="dv">200</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>coefs <span class="op">=</span> []</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> l <span class="kw">in</span> lambdas:</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  w_hat_ridge <span class="op">=</span> np.linalg.pinv(X <span class="op">@</span> X.T <span class="op">+</span> l <span class="op">*</span> np.eye(d)) <span class="op">@</span> X <span class="op">@</span> y</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  coefs.append(w_hat_ridge)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>ax.plot(lambdas, coefs)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>ax.set_xscale(<span class="st">"log"</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Œª (log scale)"</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"weights"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Ridge coefficients w.r.t Œª"</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"tight"</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display page-columns page-full">
<div class="page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><img src="w6_regularization_validation_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img column-screen-inset-left"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="lasso-regression" class="level1 page-columns page-full">
<h1>Lasso Regression</h1>
<p>The objective for the lasso regression problem is as follows:</p>
<p><span class="math display">\[\underset{w}{\arg \min} \sum_{i=1}^{n}(w^Tx_i-y_i)^2 + Œª||w||^2_1\]</span></p>
<p>The only difference between Lasso and Ridge is that Lasso uses the L1 norm (manhattan distance), in contrast to the L2 norm (euclidean distance) used by Ridge regression. This difference adds sparsity to the Lasso estimator; i.e, some feature co-efficients are pushed to 0; these features do not play a role in the final prediction.</p>
<p>In this context, Lasso can be said to perform feature-selection. Lasso also acts as a regularizer, in terms of constraining the length of the estimator.</p>
<section id="solution-for-lasso-regression" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="solution-for-lasso-regression">Solution for Lasso Regression</h2>
<p>There exists no closed form solution for Lasso, due to the constraint boundaries having points which are not differentiable.</p>
<p>Hence we may use the method of gradient descent, with the help of subgradients to find the Lasso estimator.</p>
<p>In this notebook we use scikit-learn‚Äôs implementation of Lasso to demonstrate the effect of the Lasso objective on our estimator.</p>
<div id="cell-20" class="cell page-columns page-full" data-executioninfo="{&quot;elapsed&quot;:1523,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1698641926676,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vivek Sivaramakrishnan&quot;,&quot;userId&quot;:&quot;13013544173607732074&quot;},&quot;user_tz&quot;:-330}" data-outputid="39be15c1-4c42-4eee-f97a-ef5aa0ecef79">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>lambdas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">4</span>, <span class="dv">3</span> , <span class="dv">200</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>coefs <span class="op">=</span> []</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> l <span class="kw">in</span> lambdas:</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  lasso <span class="op">=</span> Lasso(alpha<span class="op">=</span>l, max_iter<span class="op">=</span><span class="bu">int</span>(<span class="fl">1e3</span>)).fit(X.T, y)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  coefs.append(lasso.coef_)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>ax.plot(lambdas, coefs)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>ax.set_xscale(<span class="st">"log"</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Œª (log scale)"</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"weights"</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Lasso coefficients w.r.t Œª"</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"tight"</span>)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display page-columns page-full">
<div class="page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><img src="w6_regularization_validation_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img column-screen-inset-left"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="best-Œª" class="level1 page-columns page-full">
<h1>Best Œª?</h1>
<p>We discuss strategies that can be used to find Œª which reduces the MSE for our linear regression problem.</p>
<section id="validation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="validation">Validation</h2>
<ul>
<li>We partition our dataset (features and labels) into 2 - the train and validation sets respectively.</li>
<li>We construct a set of candidate values for Œª and find their corresponding estimators <span class="math inline">\(\hat{\mathbf{w}}_{\lambda - ML}\)</span> using the train dataset.</li>
<li>We then use these estimators on the validation dataset and find the MSE.</li>
<li>We choose the <span class="math inline">\(Œª\)</span> that gives the least MSE.</li>
</ul>
<div id="cell-23" class="cell page-columns page-full" data-executioninfo="{&quot;elapsed&quot;:4051,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1698642730664,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vivek Sivaramakrishnan&quot;,&quot;userId&quot;:&quot;13013544173607732074&quot;},&quot;user_tz&quot;:-330}" data-outputid="11a7636a-47ed-4803-9571-089bd5f71b34">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>candidate_lambdas <span class="op">=</span> <span class="bu">list</span>(np.logspace(<span class="op">-</span><span class="dv">9</span>, <span class="dv">2</span>, <span class="dv">1000</span>))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> X[:, :<span class="bu">int</span>(<span class="fl">0.66</span><span class="op">*</span>n)], X[:, <span class="bu">int</span>(<span class="fl">0.66</span><span class="op">*</span>n):], y[:<span class="bu">int</span>(<span class="fl">0.66</span><span class="op">*</span>n)], y[<span class="bu">int</span>(<span class="fl">0.66</span><span class="op">*</span>n):]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> validate(X_train, X_val, y_train, y_val, l):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  w_hat_l_ml <span class="op">=</span> np.linalg.pinv(X_train <span class="op">@</span> X_train.T <span class="op">+</span> l <span class="op">*</span> np.eye(d)) <span class="op">@</span> X_train <span class="op">@</span> y_train</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  l_mse <span class="op">=</span> np.linalg.norm(X_val.T <span class="op">@</span> w_hat_l_ml <span class="op">-</span> y_val)<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> <span class="bu">len</span>(y_val)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> l_mse</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>lst <span class="op">=</span> [validate(X_train, X_val, y_train, y_val, l) <span class="cf">for</span> l <span class="kw">in</span> candidate_lambdas]</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>ax.plot(candidate_lambdas, lst)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>ax.set_xscale(<span class="st">"log"</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>best_lambda, best_loss <span class="op">=</span> <span class="bu">min</span>(<span class="bu">zip</span>(candidate_lambdas, lst), key<span class="op">=</span><span class="kw">lambda</span> i: i[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_lambda, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Œª (log scale)"</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Validation Loss"</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Validation"</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"tight"</span>)<span class="op">;</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Best Lambda: </span><span class="sc">{</span>best_lambda<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best Lambda: 0.0986265846131283</code></pre>
</div>
<div class="cell-output cell-output-display page-columns page-full">
<div class="page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><img src="w6_regularization_validation_files/figure-html/cell-8-output-2.png" class="img-fluid figure-img column-screen-inset-left"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="k-fold-cross-validation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="k-fold-cross-validation">K-Fold Cross Validation</h2>
<ul>
<li>Partition dataset into K sets.</li>
<li>For each candidate <span class="math inline">\(Œª\)</span>:
<ul>
<li>For i=1 to K rounds:
<ul>
<li>Choose the ith partition as the validation set.</li>
<li>Consider the union of the remaining sets as the train set.</li>
<li>Follow aforementioned Cross Validation procedure to obtain MSE for chosen <span class="math inline">\(Œª\)</span></li>
</ul></li>
<li>Return the average MSE</li>
</ul></li>
<li>Choose the <span class="math inline">\(Œª\)</span> that gives the minimum average MSE.</li>
</ul>
<div id="cell-25" class="cell page-columns page-full" data-executioninfo="{&quot;elapsed&quot;:15439,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1698642746557,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vivek Sivaramakrishnan&quot;,&quot;userId&quot;:&quot;13013544173607732074&quot;},&quot;user_tz&quot;:-330}" data-outputid="7e736c43-5105-4359-c252-35001704a0c7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>candidate_lambdas <span class="op">=</span> <span class="bu">list</span>(np.logspace(<span class="op">-</span><span class="dv">9</span>, <span class="dv">2</span>, <span class="dv">1000</span>))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> KFold(K, l):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Construct Folds</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  folds <span class="op">=</span> []</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  n <span class="op">=</span> X.shape[<span class="dv">1</span>]<span class="op">//</span>K</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(K):</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    folds.append((X[:, i<span class="op">*</span>n:(i<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>n], y[i<span class="op">*</span>n:(i<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>n]))</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  l_mse <span class="op">=</span> np.array([])</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Cross validate over every validation partition</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(K):</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    X_val, y_val <span class="op">=</span> folds[i]</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    X_train, y_train <span class="op">=</span> np.array([[] <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(d)]), np.array([])</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(K):</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> i <span class="op">!=</span> j:</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        X_j, y_j <span class="op">=</span> folds[j]</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        X_train <span class="op">=</span> np.column_stack((X_train, X_j))</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        y_train <span class="op">=</span> np.concatenate((y_train, y_j))</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    l_mse <span class="op">=</span> np.append(l_mse, validate(X_train, X_val, y_train, y_val, l))</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(l_mse.mean())</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>lst <span class="op">=</span> []</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> l <span class="kw">in</span> candidate_lambdas:</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>  a <span class="op">=</span> KFold(<span class="dv">10</span>, l)</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>  lst.append(a)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print(l, '|', round(a, 10))</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>ax.plot(candidate_lambdas, lst)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>ax.set_xscale(<span class="st">"log"</span>)</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>best_lambda, best_loss <span class="op">=</span> <span class="bu">min</span>(<span class="bu">zip</span>(candidate_lambdas, lst), key<span class="op">=</span><span class="kw">lambda</span> i: i[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_lambda, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Œª (log scale)"</span>)</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"K-Fold Loss"</span>)</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"K-Fold CV with K=10"</span>)</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"tight"</span>)<span class="op">;</span></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Best Lambda: </span><span class="sc">{</span>best_lambda<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best Lambda: 1.0399609139541203e-06</code></pre>
</div>
<div class="cell-output cell-output-display page-columns page-full">
<div class="page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><img src="w6_regularization_validation_files/figure-html/cell-9-output-2.png" class="img-fluid figure-img column-screen-inset-left"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="leave-one-out-cross-validation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="leave-one-out-cross-validation">Leave-one-out Cross Validation</h2>
<ul>
<li>Just K-Fold Validation, but with K set to the number of samples in our dataset.</li>
<li>In other words, for n rounds, we choose just 1 element as the validation set, and the rest to be our train set.</li>
<li>It is a computationally expensive procedure to perform, although it results in a reliable and unbiased estimate of model performance.</li>
</ul>
<div id="cell-27" class="cell page-columns page-full" data-executioninfo="{&quot;elapsed&quot;:264543,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1698321523708,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vivek Sivaramakrishnan&quot;,&quot;userId&quot;:&quot;13013544173607732074&quot;},&quot;user_tz&quot;:-330}" data-outputid="7b395a8e-d0a4-4aac-f742-2c794a01b638">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>candidate_lambdas <span class="op">=</span> <span class="bu">list</span>(np.logspace(<span class="op">-</span><span class="dv">9</span>, <span class="dv">2</span>, <span class="dv">1000</span>))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>lst <span class="op">=</span> [KFold(<span class="dv">100</span>, l) <span class="cf">for</span> l <span class="kw">in</span> candidate_lambdas]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>ax.plot(candidate_lambdas, lst)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>ax.set_xscale(<span class="st">"log"</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>best_lambda, best_loss <span class="op">=</span> <span class="bu">min</span>(<span class="bu">zip</span>(candidate_lambdas, lst), key<span class="op">=</span><span class="kw">lambda</span> i: i[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_lambda, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Œª (log scale)"</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="ss">f"K-Fold (K=</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">) Loss"</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"LOOCV"</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"tight"</span>)<span class="op">;</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Best Lambda: </span><span class="sc">{</span>best_lambda<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best Lambda: 5.659170163246243e-07</code></pre>
</div>
<div class="cell-output cell-output-display page-columns page-full">
<div class="page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><img src="w6_regularization_validation_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img column-screen-inset-left"></p>
</figure>
</div>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/iamviveksrk\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>